\section{Data collection methods in pedestrian studies}
\label{chap1b:sec1}
Any endeavour to understand, model and predict pedestrian dynamics requires the collection of high-quality data on their flow, choices, decisions, preferences, and in general, their behaviour. Traditionally, monitoring and counting pedestrians have been done manually, and by recruiting human resources to observe the pedestrians on site or in the video data. Manual observations have been also a way to understand the Revealed Preferences (RP) of pedestrians. Depending on the objectives of the study, collecting data through surveys, questionnaires and interviews on hypothetical situations has also been a conventional method to understand the Stated Preferences (SP) of pedestrians and their behaviour, or to acquire information about their travel patterns. Each of the aforementioned methods carry their own advantages and disadvantages depending on the purpose of the research that the information is used in. However, all of these traditional methods share some common drawbacks that can negatively affect the quality and size of data if not addressed properly. Traditional methods of data collection are subject to possible human errors as they rely on human resource for data collection and entry~\cite{ryus2014guidebook}. Moreover, relying on human resources for data collection requires workforce recruitment and training, which can be costly, and time-consuming~\cite{lee2017emerging}. In addition, stated preferences experiments are often criticized for the lack of realism when they involve hypothetical scenarios that participants do not have prior exposure to them~\cite{farooq2018virtual}. Systematic bias due to limited number of respondents in SP experiments and interviews is another drawback in traditional approaches in data collections~\cite{wardman1988comparison}. Emergence of novel data sources in the last decade can provide potential solutions to the stated problems. In the next three subsections, an overview of these new data sources is provided in three categories: location-aware technologies for monitoring and detecting pedestrians, virtual reality tools for controlled stated preferences experiments, and open-access automated vehicle datasets for studying pedestrian behaviour from the perspective of the vehicles.       
\subsection{Location-aware technologies}
Using location-aware technologies to automate the data collection has gained popularity among scholars in different fields~\cite{farooq2015ubiquitous}. These modern approaches in data collection have led to a dramatically growing interest in utilizing them in mobility studies as an augmentation or replacement of traditional approaches. Location-aware technologies that have been used for the purpose of detecting, tracking, or counting pedestrians in the relevant research studies include: body-worn sensors, GPS data, GSM network usage data, Wi-Fi Access Point (AP) logs, Bluetooth transceivers data and RFID tags data. In general, these data collection approaches can be divided into two main categories: 1. User-Centric approaches and 2. Network-Centric approaches. \emph{User-Centric} approaches, such as GPS or body-worn sensors, require users to be actively involved in data collection process. Zheng \textit{et al.} used GPS data solely to detect mode of transportation~\cite{zheng2008understanding}. Defining features such as heading change rate, stop rate and velocity change rate and considering the conditional probability between different modes of transport, a graph-based post processing algorithm was proposed to detect network users' mode. To make the results more accurate, some researchers have used multiple data sources simultaneously. Reddy \textit{et al.}, for instance, implemented GPS data along with smartphones accelerometer data to distinguish users movements among walking, running, biking and motorized travelling~\cite{reddy2008determining}. In another study, Stenneth \textit{et al.}, added data from transportation networks to determine user mode of transport among stationery, walking, biking, driving, and using public transit~\cite{stenneth2011transportation}. Although GPS methods provide high accuracy detection, the fact that they necessitate regular users intervention and consume high levels of battery has led scholars to use other, although less accurate, sources. In addition, the need for turning on GPS sensor of the device and installing and running a mobile application to collect GPS records impedes widespread use of these data in real life mobility problems.

 In the \emph{Network-Centric} approach, such as GSM or Wi-Fi on the other hand, data can be collected passively with no intervention from users. Using cellular networks data resolves the problem of battery consumption and users intervention. The basic idea behind user geolocalization with GSM data is to acquire their location based on the identification of the Based Transceiver Stations (BTS) they are connected to in a specific time span. Sohn \textit{et al.}, for example, used coarse grained GSM data to determine whether a user is staying in a place, walking or driving~\cite{sohn2006mobility}.  Wang \textit{et al.} used coarse grained call detail records to infer transportation mode between pairs of defined origins and destinations~\cite{wang2010transportation}. Travellers were clustered into three groups using K-Means algorithm: walking, public transit and driving. Low positioning accuracy, ping-pong handover effect and privacy concerns have been mentioned in this study as some of the main problems of using GSM data. In addition, relatively low density of BTS in some areas make GSM data an unreliable source for detecting mode specially at local levels. For trips within a block or neighborhood, for instance, GSM data cannot be used as a BTS cell size is at least 200 meters~\cite{kalatian2016travel}.
 
 By implementing sensors with the ability to collect connection information from Wi-Fi enabled devices, location and movement data of users can be inferred passively with no intervention from users~\cite{farooq2015ubiquitous}. Wi-Fi enabled devices can be discovered when they are within the coverage range of a Wireless Local Area Network (WLAN), which makes it feasible to extract data from them passively.  Mun \textit{et al.} coupled Wi-Fi and GSM data to train a decision tree classification algorithm for detecting various modes of transportation~\cite{mun2008parsimonious}. Features used for classification in this experiment include: Wi-Fi signal strength Variance, duration of dominant Wi-Fi access point, number of cell IDs that device connects to and residence time in cell footprint. Using Wi-Fi data, tracking indoor movements is also feasible. Various research studies have been conducted for inferring motion in indoor environments. Krumm \textit{et al.}, for instance, used Wi-Fi signal strengths and their variance as inputs to a Hidden Markov Model for smoothing transitions between the inferred states of still and moving~\cite{krumm2004locadio}.
 
 \subsection{Controlled experiments for data collection}
 As a substitution or complementary method to surveys, interviews and stated preferences experiments, controlled experiments can be conducted to assess the pedestrian behaviour under hypothetical scenarios. In some experiments, however, scenarios may be difficult or dangerous to implement in real life. Also, it might be impossible to implement futuristic scenarios involving technologies that are not available to the researchers conducting the experiment. To address these concerns and deliver such scenarios more accurately, pictures, maps and videos have been used in the past~\cite{song2018external}. Recent developments in Virtual Reality (VR) environments have broadened the opportunities for content delivery in a more realistic way~\cite{farooq2018virtual,jennett2008measuring,animesh2011odyssey,nah2011enhancing,faiola2013correlating}. Immersion of users in the VR environment and under controlled condition, allows the evaluation of perceptions, behaviours, choices and preferences of users. Experiments in the VR environments have been conducted successfully in different fields in cognitive studies~\cite{farooq2018virtual}. A user of the VR environment can develop realistic spatial knowledge similar to that of actual physical environments~\cite{o1992effects,ruddle1997navigating}. Physical reactions of users can also be recorded in the VR environments by using electrocardiography, skin conductance or electroencephalogy and eye tracking. In the field of travel behaviour, researchers have used VR in pedestrian route choice studies~\cite{talaat2008simple} and their reaction to information in evacuation scenarios~\cite{kinateder2014virtual}. However, these studies mainly lack the interactive and dynamic potential of VR. More specifically, users in these experiments are only responsible to select routes based on the conditions exposed to them, and are incapable of interacting with other objects in the environment. In order to use the full potential of the VR technology in providing realistic experiments, actions in the VR environment needs to get responses from the elements of the environment, and vice versa. 

One of the main concerns raised in the context of using virtual reality is the level of realism involved and how the results obtained through VR resemble those obtained from behaviours in real life. Several researchers have investigated such comparison. In studies on pedestrian behaviour, Bhagavathula \textit{et al.} compared different elements of pedestrian behaviour in virtual reality and real environments~\cite{bhagavathula2018reality}. Their comparison suggested that the crossing intention, perception of safety, perception of risk and perception of distance were not significantly different in the two environments. On the other hand, it was concluded that the perception of speed in the two approaches of data collection were different among the participants. Similarly, Deb \textit{et al.} compared the behaviour of pedestrians crossing a signalized intersection and concluded that both objective and subjective measures were similar in the participants in the two environments~\cite{deb2017efficacy}. However, an 11\% failure in completing the VR experiments was observed during their data collection, which was a result of motion sickness experienced by the participants. In another study focused on body movements of pedestrians crossing in virtual reality environments, Kalantarov \textit{et al.} concluded that wait time measures in their virtual realty experiment was in line with the laboratory studies and field observations~\cite{kalantarov2018pedestrians}.

\subsection{Open-access AV datasets}
The emergence of automated vehicles has led leading manufacturers and research centers to collect and analyze data using potential AV sensors. Automated vehicles are equipped with several sensors and cameras to detect and explore objects in their surrounding area. Investigating the data and the information that AVs can capture can provide remarkable opportunities for researchers to predict and understand the forthcoming challenges of future urban areas. In this subsection, we review some of the well-known open-access AV datasets. 

Throughout this subsection, we use a number of terms and abbreviations to discuss AV datasets. These terms include:
\begin{itemize}
    \item Ego vehicle: As the operational level of AVs is still limited, some companies and research centers have installed AV sensors on regular vehicles to collect similar to a hypothetical AV. The vehicle that contains the sensors and collects the data is often called the ego vehicle. Some manufacturers use actual AVs as the ego vehicle. 
    \item LIDAR: AVs can be equipped with various sensors. Light Detection and Ranging (LIDAR) is one of the most popular methods in AVs to create a 3D model of the surrounding environment. LIDAR sensors measure distances to the surrounding objects by sending laser pulses to the target and capturing the reflection with a sensor. Using LIDAR sensors as a complementary tool to the video cameras help AVs overcome problems such as occlusion and distortion in video data. 
    \item Annotation: Raw AV datasets contain video and LIDAR data, which often require expert knowledge to process and retrieve useful information. To facilitate the utilization of these data, open-access AV datasets often provide a labelling (manually or automated) of different objects detected in the videos.
\end{itemize}

One of the earliest pioneers of AV datasets is the  Karlsruhe Institute of Technology
and Toyota Technological Institute (KITTI) group. First released in 2012, KITTI dataset is primarily focused on the video data from the cameras installed on an ego vehicle, with GPS and LIDAR data providing the ground truth. With benchmarks provided for different tasks, KITTI is a well-established open-access dataset. However, KITTI is often criticized for a focus on rural areas and highways, and a lack of long enough tracks~\cite{Geiger2013IJRR}. NuScenes is another well-established AV dataset containing 1,000 scenes of 20 seconds length~\cite{nuscenes2019}. Ego vehicles used in nuScenes' data collection contain cameras, LIDAR, RADAR, GPS, and Inertial Measurement Unit (IMU) sensors. Contrary to KITTI, nuScenes includes data from driving in congested urban areas of Boston and Singapore, which makes it a suitable match for studying modern urban spaces. Twenty-three classes of objects are annotated in the dataset, including pedestrians, children, bicycles, construction zones, etc. NuScenes data also include the underlying maps of the drives, which makes it possible to extract some contextual information about the scenes. Although the dataset is collected in different weather conditions, information about the weather is not provided in the dataset and needs to be extracted by processing frames and videos. 
Another dataset built upon nuScenes data format is Lyft Level 5 open data~\cite{lyft2019}. Lyft level 5 dataset provides 2.5 hours of automated driving in Palo Alto, California. Similar to nuScenes, underlying maps, annotations and different weather conditions are included in the dataset. Although it is relatively new, using the same database format as nuScenes gives Lyft level 5 dataset a robust and well-documented structure. The relatively small size of the collected data is the major drawback of Lyft dataset. Ford multi-AV seasonal dataset~\cite{agarwal2020ford} is another relatively new and large dataset concentrated on providing diverse environmental conditions within the data. With a 66 $km$ road coverage over one year of data collection, Ford AV dataset is considered as one of the most extensive datasets regarding its coverage and diversity. However, not providing annotations make this dataset challenging to use in a lot of domains. Google's Waymo dataset is the largest and most annotated AV data currently available ~\cite{sun2020scalability}. With  1,150 scenes of over 6 hours of driving, the covered 76 $km^2$ area in the Waymo dataset is the largest among all the available datasets. Extensive hours of data collection include driving in night time and daylight, construction areas, downtown and suburban areas, and diverse weather conditions.  However, unlike other popular AV datasets, Waymo currently does not provide an underlying map of the drives, making utilization of contextual information from the map impossible.       





 


